Namespace(seed=42, GPU_to_use=0, epochs=200, batch_size=128, lr=0.0005, lr_decay=200, gamma=0.5, training_samples=0, test_samples=0, prediction_steps=10, encoder_hidden=256, decoder_hidden=256, encoder='cnn', decoder='mlp', prior=1, edge_types=2, dont_use_encoder=False, lr_z=0.1, global_temp=False, load_temperatures=False, alpha=2, num_cats=3, unobserved=0, model_unobserved=0, dont_shuffle_unobserved=False, teacher_forcing=0, suffix='netsim', timesteps=200, num_atoms=15, dims=1, datadir='./data', save_folder='cnn_netsim', expername='', sym_save_folder='../logs', load_folder='', test_time_adapt=False, lr_logits=0.01, num_tta_steps=100, dont_skip_first=True, temp=0.5, hard=False, no_validate=True, no_cuda=False, var=5e-07, encoder_dropout=0.0, decoder_dropout=0.0, no_factor=False, test=False, device=device(type='cuda', index=0), cuda=True, factor=True, validate=False, shuffle_unobserved=True, skip_first=False, use_encoder=True, time='2025-05-21T13:15:16.319612', num_GPU=1, batch_size_multiGPU=128, log_path='cnn_netsim\\2025-05-21T13.15.16.319612')
Using GPU #0
DataParallel(
  (module): CNNEncoder(
    (cnn): CNN(
      (pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (conv1): Conv1d(2, 256, kernel_size=(5,), stride=(1,))
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv1d(256, 256, kernel_size=(5,), stride=(1,))
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv_predict): Conv1d(256, 256, kernel_size=(1,), stride=(1,))
      (conv_attention): Conv1d(256, 1, kernel_size=(1,), stride=(1,))
    )
    (mlp1): MLP(
      (fc1): Linear(in_features=256, out_features=256, bias=True)
      (fc2): Linear(in_features=256, out_features=256, bias=True)
      (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (mlp2): MLP(
      (fc1): Linear(in_features=256, out_features=256, bias=True)
      (fc2): Linear(in_features=256, out_features=256, bias=True)
      (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (mlp3): MLP(
      (fc1): Linear(in_features=768, out_features=256, bias=True)
      (fc2): Linear(in_features=256, out_features=256, bias=True)
      (bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fc_out): Linear(in_features=256, out_features=2, bias=True)
  )
)
DataParallel(
  (module): MLPDecoder(
    (msg_fc1): ModuleList(
      (0-1): 2 x Linear(in_features=2, out_features=256, bias=True)
    )
    (msg_fc2): ModuleList(
      (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)
    )
    (out_fc1): Linear(in_features=257, out_features=256, bias=True)
    (out_fc2): Linear(in_features=256, out_features=256, bias=True)
    (out_fc3): Linear(in_features=256, out_features=1, bias=True)
  )
)
0 train	 	loss_kl -7.1391463280 	acc 0.5019047619 	auroc 0.5303703704 	loss_nll 18651752.0000000000 	loss_mse 0.0937273949 	loss 18651744.0000000000 	inference time 1.2098286152 	time: 6.7248s 	
1 train	 	loss_kl -4.9214673042 	acc 0.4980952381 	auroc 0.5300347222 	loss_nll 27208052.0000000000 	loss_mse 0.1367238909 	loss 27208048.0000000000 	inference time 0.3328864574 	time: 5.3697s 	
2 train	 	loss_kl -3.2741587162 	acc 0.5257142857 	auroc 0.5258796296 	loss_nll 17336002.0000000000 	loss_mse 0.0871155784 	loss 17335998.0000000000 	inference time 0.2681436539 	time: 5.2915s 	
3 train	 	loss_kl -2.8220300674 	acc 0.5028571429 	auroc 0.5246932870 	loss_nll 21606762.0000000000 	loss_mse 0.1085767075 	loss 21606760.0000000000 	inference time 0.3231425285 	time: 5.4337s 	
4 train	 	loss_kl -2.5127410889 	acc 0.5000000000 	auroc 0.5289236111 	loss_nll 18376630.0000000000 	loss_mse 0.0923448727 	loss 18376628.0000000000 	inference time 0.2615981102 	time: 5.2636s 	
5 train	 	loss_kl -2.4122691154 	acc 0.5133333333 	auroc 0.5346875000 	loss_nll 18408958.0000000000 	loss_mse 0.0925073251 	loss 18408956.0000000000 	inference time 0.2369570732 	time: 5.2110s 	
6 train	 	loss_kl -2.1301791668 	acc 0.5257142857 	auroc 0.5474016204 	loss_nll 16183266.0000000000 	loss_mse 0.0813229308 	loss 16183264.0000000000 	inference time 0.3741304874 	time: 5.4182s 	
7 train	 	loss_kl -1.9919856787 	acc 0.5342857143 	auroc 0.5526909722 	loss_nll 14073861.0000000000 	loss_mse 0.0707229227 	loss 14073859.0000000000 	inference time 0.3468527794 	time: 5.3951s 	
8 train	 	loss_kl -1.8398687840 	acc 0.5390476190 	auroc 0.5599305556 	loss_nll 13854172.0000000000 	loss_mse 0.0696189627 	loss 13854170.0000000000 	inference time 0.3979558945 	time: 5.4025s 	
9 train	 	loss_kl -1.6171693802 	acc 0.5304761905 	auroc 0.5542881944 	loss_nll 13600524.0000000000 	loss_mse 0.0683443472 	loss 13600522.0000000000 	inference time 0.3650288582 	time: 5.3742s 	
10 train	 	loss_kl -1.5406429768 	acc 0.5200000000 	auroc 0.5571006944 	loss_nll 13086088.0000000000 	loss_mse 0.0657592341 	loss 13086086.0000000000 	inference time 0.3826072216 	time: 5.3899s 	
11 train	 	loss_kl -1.6875345707 	acc 0.5161904762 	auroc 0.5472222222 	loss_nll 12921653.0000000000 	loss_mse 0.0649329275 	loss 12921651.0000000000 	inference time 0.2832152843 	time: 5.3515s 	
12 train	 	loss_kl -1.7120662928 	acc 0.5161904762 	auroc 0.5361747685 	loss_nll 13378084.0000000000 	loss_mse 0.0672265515 	loss 13378082.0000000000 	inference time 0.2884955406 	time: 5.3974s 	
13 train	 	loss_kl -1.5962717533 	acc 0.5133333333 	auroc 0.5381018519 	loss_nll 13553779.0000000000 	loss_mse 0.0681094453 	loss 13553777.0000000000 	inference time 0.2540957928 	time: 5.3128s 	
14 train	 	loss_kl -1.4856586456 	acc 0.4990476190 	auroc 0.5400173611 	loss_nll 13159472.0000000000 	loss_mse 0.0661280006 	loss 13159471.0000000000 	inference time 0.2540535927 	time: 5.3041s 	
15 train	 	loss_kl -1.4599157572 	acc 0.4971428571 	auroc 0.5326909722 	loss_nll 13149456.0000000000 	loss_mse 0.0660776645 	loss 13149455.0000000000 	inference time 0.4179530144 	time: 5.3431s 	
16 train	 	loss_kl -1.4426196814 	acc 0.5047619048 	auroc 0.5307060185 	loss_nll 13098204.0000000000 	loss_mse 0.0658201128 	loss 13098203.0000000000 	inference time 0.3217422962 	time: 5.3356s 	
17 train	 	loss_kl -1.3682343960 	acc 0.5247619048 	auroc 0.5261747685 	loss_nll 12924884.0000000000 	loss_mse 0.0649491623 	loss 12924883.0000000000 	inference time 0.3313791752 	time: 5.3206s 	
18 train	 	loss_kl -1.3831913471 	acc 0.5180952381 	auroc 0.5240219907 	loss_nll 12945839.0000000000 	loss_mse 0.0650544614 	loss 12945838.0000000000 	inference time 0.3959383965 	time: 5.4787s 	
19 train	 	loss_kl -1.3707102537 	acc 0.5190476190 	auroc 0.5240625000 	loss_nll 13040806.0000000000 	loss_mse 0.0655316785 	loss 13040805.0000000000 	inference time 0.2409501076 	time: 5.3660s 	
20 train	 	loss_kl -1.3586580753 	acc 0.5247619048 	auroc 0.5233449074 	loss_nll 12949771.0000000000 	loss_mse 0.0650742278 	loss 12949770.0000000000 	inference time 0.3329124451 	time: 5.7951s 	
21 train	 	loss_kl -1.2690020800 	acc 0.5190476190 	auroc 0.5196064815 	loss_nll 12902609.0000000000 	loss_mse 0.0648372248 	loss 12902608.0000000000 	inference time 0.3079359531 	time: 5.4942s 	
22 train	 	loss_kl -1.1828886271 	acc 0.5152380952 	auroc 0.5158680556 	loss_nll 12936263.0000000000 	loss_mse 0.0650063455 	loss 12936262.0000000000 	inference time 0.2309308052 	time: 5.4961s 	
23 train	 	loss_kl -1.1340000629 	acc 0.5057142857 	auroc 0.5126099537 	loss_nll 12896490.0000000000 	loss_mse 0.0648064762 	loss 12896489.0000000000 	inference time 0.4105441570 	time: 5.6089s 	
24 train	 	loss_kl -1.1546965837 	acc 0.5028571429 	auroc 0.5088831019 	loss_nll 12833078.0000000000 	loss_mse 0.0644878298 	loss 12833077.0000000000 	inference time 0.2452270985 	time: 5.4963s 	
25 train	 	loss_kl -1.1372867823 	acc 0.4923809524 	auroc 0.5070775463 	loss_nll 12839240.0000000000 	loss_mse 0.0645187870 	loss 12839239.0000000000 	inference time 0.2572872639 	time: 5.3523s 	
26 train	 	loss_kl -1.1264781952 	acc 0.4942857143 	auroc 0.5052777778 	loss_nll 12855530.0000000000 	loss_mse 0.0646006539 	loss 12855529.0000000000 	inference time 0.3138728142 	time: 5.5380s 	
27 train	 	loss_kl -1.1370749474 	acc 0.5000000000 	auroc 0.5038136574 	loss_nll 12838580.0000000000 	loss_mse 0.0645154789 	loss 12838579.0000000000 	inference time 0.3611631393 	time: 5.4002s 	
28 train	 	loss_kl -1.1304548979 	acc 0.5019047619 	auroc 0.5020601852 	loss_nll 12845419.0000000000 	loss_mse 0.0645498410 	loss 12845418.0000000000 	inference time 0.4208488464 	time: 5.3892s 	
29 train	 	loss_kl -1.0859359503 	acc 0.4980952381 	auroc 0.5006886574 	loss_nll 12863807.0000000000 	loss_mse 0.0646422431 	loss 12863806.0000000000 	inference time 0.3006048203 	time: 5.4175s 	
30 train	 	loss_kl -1.0263046026 	acc 0.4971428571 	auroc 0.5025636574 	loss_nll 12848142.0000000000 	loss_mse 0.0645635352 	loss 12848141.0000000000 	inference time 0.3952224255 	time: 5.3884s 	
31 train	 	loss_kl -0.9868159294 	acc 0.4990476190 	auroc 0.5060937500 	loss_nll 12841408.0000000000 	loss_mse 0.0645296946 	loss 12841407.0000000000 	inference time 0.3331105709 	time: 5.4086s 	
32 train	 	loss_kl -0.9679445624 	acc 0.5009523810 	auroc 0.5056539352 	loss_nll 12850098.0000000000 	loss_mse 0.0645733550 	loss 12850097.0000000000 	inference time 0.2058043480 	time: 5.4672s 	
33 train	 	loss_kl -0.9693339467 	acc 0.5038095238 	auroc 0.5058680556 	loss_nll 12838450.0000000000 	loss_mse 0.0645148233 	loss 12838449.0000000000 	inference time 0.3445277214 	time: 5.6233s 	
34 train	 	loss_kl -0.9636178613 	acc 0.5038095238 	auroc 0.5059490741 	loss_nll 12826466.0000000000 	loss_mse 0.0644546077 	loss 12826465.0000000000 	inference time 0.2795536518 	time: 5.3334s 	
35 train	 	loss_kl -0.9628658295 	acc 0.5047619048 	auroc 0.5063888889 	loss_nll 12829835.0000000000 	loss_mse 0.0644715279 	loss 12829834.0000000000 	inference time 0.3665568829 	time: 5.5449s 	
36 train	 	loss_kl -0.9633729458 	acc 0.5057142857 	auroc 0.5060185185 	loss_nll 12826728.0000000000 	loss_mse 0.0644559190 	loss 12826727.0000000000 	inference time 0.2735383511 	time: 5.4757s 	
37 train	 	loss_kl -0.9647650123 	acc 0.5028571429 	auroc 0.5047858796 	loss_nll 12818646.0000000000 	loss_mse 0.0644153059 	loss 12818645.0000000000 	inference time 0.3530516624 	time: 5.6989s 	
38 train	 	loss_kl -0.9811561108 	acc 0.5047619048 	auroc 0.5027951389 	loss_nll 12823368.0000000000 	loss_mse 0.0644390360 	loss 12823367.0000000000 	inference time 0.4127528667 	time: 5.4717s 	
39 train	 	loss_kl -0.9943657517 	acc 0.5028571429 	auroc 0.5030555556 	loss_nll 12818079.0000000000 	loss_mse 0.0644124597 	loss 12818078.0000000000 	inference time 0.3639628887 	time: 5.5205s 	
40 train	 	loss_kl -1.0037548542 	acc 0.5047619048 	auroc 0.5032754630 	loss_nll 12813017.0000000000 	loss_mse 0.0643870160 	loss 12813016.0000000000 	inference time 0.1658031940 	time: 5.3255s 	
41 train	 	loss_kl -1.0088877678 	acc 0.5057142857 	auroc 0.5032928241 	loss_nll 12815345.0000000000 	loss_mse 0.0643987209 	loss 12815344.0000000000 	inference time 0.2928926945 	time: 5.4246s 	
42 train	 	loss_kl -1.0058412552 	acc 0.5057142857 	auroc 0.5034317130 	loss_nll 12813910.0000000000 	loss_mse 0.0643915012 	loss 12813909.0000000000 	inference time 0.0723245144 	time: 5.2693s 	
43 train	 	loss_kl -0.9951029420 	acc 0.5019047619 	auroc 0.5028703704 	loss_nll 12810262.0000000000 	loss_mse 0.0643731728 	loss 12810261.0000000000 	inference time 0.2770872116 	time: 5.3882s 	
44 train	 	loss_kl -0.9774600267 	acc 0.5019047619 	auroc 0.5026620370 	loss_nll 12811218.0000000000 	loss_mse 0.0643779784 	loss 12811217.0000000000 	inference time 0.3005201817 	time: 5.4326s 	
45 train	 	loss_kl -0.9791662097 	acc 0.5019047619 	auroc 0.5023958333 	loss_nll 12809025.0000000000 	loss_mse 0.0643669590 	loss 12809024.0000000000 	inference time 0.3219845295 	time: 5.4461s 	
46 train	 	loss_kl -0.9938651919 	acc 0.5009523810 	auroc 0.5022511574 	loss_nll 12808035.0000000000 	loss_mse 0.0643619895 	loss 12808034.0000000000 	inference time 0.3966286182 	time: 5.6052s 	
47 train	 	loss_kl -0.9912502170 	acc 0.5057142857 	auroc 0.5017361111 	loss_nll 12809114.0000000000 	loss_mse 0.0643673986 	loss 12809113.0000000000 	inference time 0.2810137272 	time: 5.4188s 	
48 train	 	loss_kl -1.0138916969 	acc 0.5076190476 	auroc 0.5018807870 	loss_nll 12805947.0000000000 	loss_mse 0.0643514916 	loss 12805946.0000000000 	inference time 0.2691216469 	time: 5.3880s 	
49 train	 	loss_kl -1.0092444420 	acc 0.5142857143 	auroc 0.5015046296 	loss_nll 12806121.0000000000 	loss_mse 0.0643523708 	loss 12806120.0000000000 	inference time 0.3335235119 	time: 5.8542s 	
50 train	 	loss_kl -1.0147713423 	acc 0.5180952381 	auroc 0.5010648148 	loss_nll 12805571.0000000000 	loss_mse 0.0643495992 	loss 12805570.0000000000 	inference time 0.3670530319 	time: 5.5291s 	
51 train	 	loss_kl -1.0106608868 	acc 0.5171428571 	auroc 0.5001099537 	loss_nll 12802922.0000000000 	loss_mse 0.0643362924 	loss 12802921.0000000000 	inference time 0.2595300674 	time: 5.3756s 	
52 train	 	loss_kl -0.9867956638 	acc 0.5180952381 	auroc 0.4999537037 	loss_nll 12803150.0000000000 	loss_mse 0.0643374324 	loss 12803149.0000000000 	inference time 0.2647581100 	time: 5.3508s 	
53 train	 	loss_kl -0.9745416641 	acc 0.5152380952 	auroc 0.4996585648 	loss_nll 12799649.0000000000 	loss_mse 0.0643198416 	loss 12799648.0000000000 	inference time 0.4065818787 	time: 5.5652s 	
54 train	 	loss_kl -0.9810564518 	acc 0.5123809524 	auroc 0.4992476852 	loss_nll 12800692.0000000000 	loss_mse 0.0643250868 	loss 12800691.0000000000 	inference time 0.3282518387 	time: 5.4721s 	
55 train	 	loss_kl -0.9843040109 	acc 0.5085714286 	auroc 0.4998437500 	loss_nll 12798306.0000000000 	loss_mse 0.0643130988 	loss 12798305.0000000000 	inference time 0.4002108574 	time: 5.5606s 	
56 train	 	loss_kl -0.9894152284 	acc 0.5085714286 	auroc 0.4998090278 	loss_nll 12796981.0000000000 	loss_mse 0.0643064454 	loss 12796980.0000000000 	inference time 0.2365376949 	time: 5.3218s 	
57 train	 	loss_kl -0.9878106117 	acc 0.5066666667 	auroc 0.4993287037 	loss_nll 12795199.0000000000 	loss_mse 0.0642974824 	loss 12795198.0000000000 	inference time 0.3146116734 	time: 5.4725s 	
58 train	 	loss_kl -0.9762364030 	acc 0.5066666667 	auroc 0.4988773148 	loss_nll 12793366.0000000000 	loss_mse 0.0642882735 	loss 12793365.0000000000 	inference time 0.4111037254 	time: 5.5307s 	
59 train	 	loss_kl -0.9684588909 	acc 0.5076190476 	auroc 0.4980034722 	loss_nll 12791832.0000000000 	loss_mse 0.0642805621 	loss 12791831.0000000000 	inference time 0.3856465816 	time: 5.4565s 	
60 train	 	loss_kl -0.9665024281 	acc 0.5038095238 	auroc 0.4968229167 	loss_nll 12792595.0000000000 	loss_mse 0.0642843992 	loss 12792594.0000000000 	inference time 0.3815071583 	time: 5.4823s 	
61 train	 	loss_kl -0.9696403146 	acc 0.5019047619 	auroc 0.4972395833 	loss_nll 12792453.0000000000 	loss_mse 0.0642836839 	loss 12792452.0000000000 	inference time 0.3459184170 	time: 5.4947s 	
62 train	 	loss_kl -0.9753125310 	acc 0.5028571429 	auroc 0.4991435185 	loss_nll 12789880.0000000000 	loss_mse 0.0642707571 	loss 12789879.0000000000 	inference time 0.3070793152 	time: 5.4530s 	
63 train	 	loss_kl -0.9783425331 	acc 0.5019047619 	auroc 0.4995833333 	loss_nll 12788774.0000000000 	loss_mse 0.0642651990 	loss 12788773.0000000000 	inference time 0.3568844795 	time: 5.4685s 	
64 train	 	loss_kl -0.9687153101 	acc 0.5028571429 	auroc 0.4996701389 	loss_nll 12788092.0000000000 	loss_mse 0.0642617643 	loss 12788091.0000000000 	inference time 0.2912008762 	time: 5.4313s 	
65 train	 	loss_kl -0.9629412293 	acc 0.5028571429 	auroc 0.5000636574 	loss_nll 12785349.0000000000 	loss_mse 0.0642479882 	loss 12785348.0000000000 	inference time 0.3950572014 	time: 5.4269s 	
66 train	 	loss_kl -0.9550880194 	acc 0.5066666667 	auroc 0.5002199074 	loss_nll 12785038.0000000000 	loss_mse 0.0642464161 	loss 12785037.0000000000 	inference time 0.3636622429 	time: 5.4491s 	
67 train	 	loss_kl -0.9487855434 	acc 0.5104761905 	auroc 0.5003125000 	loss_nll 12784121.0000000000 	loss_mse 0.0642418116 	loss 12784120.0000000000 	inference time 0.2933640480 	time: 5.4147s 	
68 train	 	loss_kl -0.9481828809 	acc 0.5085714286 	auroc 0.4986458333 	loss_nll 12783732.0000000000 	loss_mse 0.0642398596 	loss 12783731.0000000000 	inference time 0.3009159565 	time: 5.4133s 	
69 train	 	loss_kl -0.9403540492 	acc 0.5104761905 	auroc 0.4968171296 	loss_nll 12782634.0000000000 	loss_mse 0.0642343387 	loss 12782633.0000000000 	inference time 0.2988011837 	time: 5.4050s 	
70 train	 	loss_kl -0.9263063669 	acc 0.5076190476 	auroc 0.4953182870 	loss_nll 12780923.0000000000 	loss_mse 0.0642257407 	loss 12780922.0000000000 	inference time 0.2853360176 	time: 5.4084s 	
71 train	 	loss_kl -0.9177111983 	acc 0.5085714286 	auroc 0.4931134259 	loss_nll 12781076.0000000000 	loss_mse 0.0642265081 	loss 12781075.0000000000 	inference time 0.2637314796 	time: 5.4208s 	
72 train	 	loss_kl -0.9073976874 	acc 0.5095238095 	auroc 0.4930844907 	loss_nll 12778018.0000000000 	loss_mse 0.0642111450 	loss 12778017.0000000000 	inference time 0.2804410458 	time: 5.3800s 	
73 train	 	loss_kl -0.8976506591 	acc 0.5104761905 	auroc 0.4942245370 	loss_nll 12775114.0000000000 	loss_mse 0.0641965494 	loss 12775113.0000000000 	inference time 0.3338558674 	time: 5.3454s 	
74 train	 	loss_kl -0.8913801312 	acc 0.5085714286 	auroc 0.4943865741 	loss_nll 12775480.0000000000 	loss_mse 0.0641983822 	loss 12775479.0000000000 	inference time 0.3644864559 	time: 5.5217s 	
75 train	 	loss_kl -0.8985762000 	acc 0.5066666667 	auroc 0.4944386574 	loss_nll 12774723.0000000000 	loss_mse 0.0641945899 	loss 12774722.0000000000 	inference time 0.2701928616 	time: 5.3188s 	
76 train	 	loss_kl -0.9134941101 	acc 0.5085714286 	auroc 0.4930613426 	loss_nll 12772287.0000000000 	loss_mse 0.0641823485 	loss 12772286.0000000000 	inference time 0.4253258705 	time: 5.5665s 	
77 train	 	loss_kl -0.9210931659 	acc 0.5085714286 	auroc 0.4926620370 	loss_nll 12771055.0000000000 	loss_mse 0.0641761497 	loss 12771054.0000000000 	inference time 0.3018741608 	time: 5.4781s 	
78 train	 	loss_kl -0.9238995314 	acc 0.5066666667 	auroc 0.4925868056 	loss_nll 12773332.0000000000 	loss_mse 0.0641875938 	loss 12773331.0000000000 	inference time 0.2688765526 	time: 5.3455s 	
79 train	 	loss_kl -0.9138401747 	acc 0.5047619048 	auroc 0.4921527778 	loss_nll 12770635.0000000000 	loss_mse 0.0641740412 	loss 12770634.0000000000 	inference time 0.3947765827 	time: 5.4890s 	
80 train	 	loss_kl -0.8881139159 	acc 0.5085714286 	auroc 0.4910648148 	loss_nll 12768814.0000000000 	loss_mse 0.0641648918 	loss 12768813.0000000000 	inference time 0.2851979733 	time: 5.3361s 	
81 train	 	loss_kl -0.8599625826 	acc 0.5057142857 	auroc 0.4912442130 	loss_nll 12769640.0000000000 	loss_mse 0.0641690493 	loss 12769639.0000000000 	inference time 0.3672125340 	time: 5.5373s 	
82 train	 	loss_kl -0.8410148025 	acc 0.5066666667 	auroc 0.4908449074 	loss_nll 12767454.0000000000 	loss_mse 0.0641580597 	loss 12767453.0000000000 	inference time 0.2800300121 	time: 5.4589s 	
83 train	 	loss_kl -0.8320677876 	acc 0.5057142857 	auroc 0.4905787037 	loss_nll 12765230.0000000000 	loss_mse 0.0641468912 	loss 12765229.0000000000 	inference time 0.2753298283 	time: 5.8831s 	
84 train	 	loss_kl -0.8322898746 	acc 0.5057142857 	auroc 0.4902777778 	loss_nll 12764292.0000000000 	loss_mse 0.0641421601 	loss 12764291.0000000000 	inference time 0.2991144657 	time: 5.4097s 	
85 train	 	loss_kl -0.8421407342 	acc 0.5057142857 	auroc 0.4906307870 	loss_nll 12761410.0000000000 	loss_mse 0.0641276836 	loss 12761409.0000000000 	inference time 0.2510781288 	time: 5.2749s 	
86 train	 	loss_kl -0.8448989987 	acc 0.5095238095 	auroc 0.4910416667 	loss_nll 12760185.0000000000 	loss_mse 0.0641215369 	loss 12760184.0000000000 	inference time 0.3098070621 	time: 5.3583s 	
87 train	 	loss_kl -0.8461736441 	acc 0.5085714286 	auroc 0.4902893519 	loss_nll 12761410.0000000000 	loss_mse 0.0641276911 	loss 12761409.0000000000 	inference time 0.2461562157 	time: 5.4925s 	
88 train	 	loss_kl -0.8512431979 	acc 0.5104761905 	auroc 0.4895196759 	loss_nll 12761999.0000000000 	loss_mse 0.0641306415 	loss 12761998.0000000000 	inference time 0.2846679688 	time: 5.5930s 	
89 train	 	loss_kl -0.8404710889 	acc 0.5095238095 	auroc 0.4909837963 	loss_nll 12757769.0000000000 	loss_mse 0.0641093925 	loss 12757768.0000000000 	inference time 0.2715373039 	time: 5.5875s 	
90 train	 	loss_kl -0.8342178464 	acc 0.5114285714 	auroc 0.4916550926 	loss_nll 12757313.0000000000 	loss_mse 0.0641070977 	loss 12757312.0000000000 	inference time 0.3380365372 	time: 5.5094s 	
91 train	 	loss_kl -0.8175790310 	acc 0.5076190476 	auroc 0.4923437500 	loss_nll 12757737.0000000000 	loss_mse 0.0641092286 	loss 12757736.0000000000 	inference time 0.2854607105 	time: 5.7849s 	
92 train	 	loss_kl -0.8070343733 	acc 0.5076190476 	auroc 0.4939178241 	loss_nll 12753809.0000000000 	loss_mse 0.0640894920 	loss 12753808.0000000000 	inference time 0.2962725163 	time: 5.5467s 	
93 train	 	loss_kl -0.8028233051 	acc 0.5076190476 	auroc 0.4958796296 	loss_nll 12756631.0000000000 	loss_mse 0.0641036704 	loss 12756630.0000000000 	inference time 0.3636856079 	time: 5.5039s 	
94 train	 	loss_kl -0.8039956689 	acc 0.5066666667 	auroc 0.4986805556 	loss_nll 12751942.0000000000 	loss_mse 0.0640801042 	loss 12751941.0000000000 	inference time 0.2901484966 	time: 5.3377s 	
95 train	 	loss_kl -0.8022983670 	acc 0.5085714286 	auroc 0.4982175926 	loss_nll 12750645.0000000000 	loss_mse 0.0640735924 	loss 12750644.0000000000 	inference time 0.3157033920 	time: 5.5671s 	
96 train	 	loss_kl -0.8162761927 	acc 0.5076190476 	auroc 0.4989062500 	loss_nll 12751348.0000000000 	loss_mse 0.0640771240 	loss 12751347.0000000000 	inference time 0.3011453152 	time: 5.5163s 	
97 train	 	loss_kl -0.8301709294 	acc 0.5057142857 	auroc 0.4988425926 	loss_nll 12747843.0000000000 	loss_mse 0.0640595034 	loss 12747842.0000000000 	inference time 0.4121012688 	time: 5.7293s 	
98 train	 	loss_kl -0.8452374339 	acc 0.5066666667 	auroc 0.4979166667 	loss_nll 12748268.0000000000 	loss_mse 0.0640616417 	loss 12748267.0000000000 	inference time 0.3667097092 	time: 5.6360s 	
99 train	 	loss_kl -0.8447740078 	acc 0.5066666667 	auroc 0.4983217593 	loss_nll 12745787.0000000000 	loss_mse 0.0640491843 	loss 12745786.0000000000 	inference time 0.3463013172 	time: 5.4918s 	
100 train	 	loss_kl -0.8249459267 	acc 0.5066666667 	auroc 0.4975520833 	loss_nll 12746175.0000000000 	loss_mse 0.0640511289 	loss 12746174.0000000000 	inference time 0.2826671600 	time: 5.4678s 	
101 train	 	loss_kl -0.7981692553 	acc 0.5066666667 	auroc 0.4971412037 	loss_nll 12744087.0000000000 	loss_mse 0.0640406385 	loss 12744086.0000000000 	inference time 0.3473863602 	time: 5.4648s 	
102 train	 	loss_kl -0.7774637938 	acc 0.5047619048 	auroc 0.4971064815 	loss_nll 12741497.0000000000 	loss_mse 0.0640276149 	loss 12741496.0000000000 	inference time 0.2866311073 	time: 5.3312s 	
103 train	 	loss_kl -0.7681981325 	acc 0.5028571429 	auroc 0.4967592593 	loss_nll 12742459.0000000000 	loss_mse 0.0640324578 	loss 12742458.0000000000 	inference time 0.4101927280 	time: 5.4576s 	
104 train	 	loss_kl -0.7669193745 	acc 0.5000000000 	auroc 0.4964351852 	loss_nll 12741260.0000000000 	loss_mse 0.0640264228 	loss 12741259.0000000000 	inference time 0.3756582737 	time: 5.4413s 	
105 train	 	loss_kl -0.7624436617 	acc 0.5009523810 	auroc 0.4965219907 	loss_nll 12741487.0000000000 	loss_mse 0.0640275702 	loss 12741486.0000000000 	inference time 0.3991296291 	time: 5.4845s 	
106 train	 	loss_kl -0.7498632669 	acc 0.5019047619 	auroc 0.4963831019 	loss_nll 12737290.0000000000 	loss_mse 0.0640064850 	loss 12737289.0000000000 	inference time 0.2216989994 	time: 5.2659s 	
107 train	 	loss_kl -0.7379881740 	acc 0.5028571429 	auroc 0.4960069444 	loss_nll 12738081.0000000000 	loss_mse 0.0640104562 	loss 12738080.0000000000 	inference time 0.3536393642 	time: 5.4136s 	
108 train	 	loss_kl -0.7270898819 	acc 0.5019047619 	auroc 0.4972337963 	loss_nll 12735801.0000000000 	loss_mse 0.0639990047 	loss 12735800.0000000000 	inference time 0.3986878395 	time: 5.4300s 	
109 train	 	loss_kl -0.7313286662 	acc 0.5019047619 	auroc 0.4971585648 	loss_nll 12733613.0000000000 	loss_mse 0.0639880002 	loss 12733612.0000000000 	inference time 0.3879408836 	time: 5.4237s 	
110 train	 	loss_kl -0.7492154837 	acc 0.4990476190 	auroc 0.4970891204 	loss_nll 12734915.0000000000 	loss_mse 0.0639945418 	loss 12734914.0000000000 	inference time 0.3905396461 	time: 5.4207s 	
111 train	 	loss_kl -0.7608508468 	acc 0.4980952381 	auroc 0.4969618056 	loss_nll 12732367.0000000000 	loss_mse 0.0639817417 	loss 12732366.0000000000 	inference time 0.3517334461 	time: 5.3435s 	
112 train	 	loss_kl -0.7716866136 	acc 0.4961904762 	auroc 0.4975462963 	loss_nll 12735029.0000000000 	loss_mse 0.0639951229 	loss 12735028.0000000000 	inference time 0.3117249012 	time: 5.3769s 	
113 train	 	loss_kl -0.7859541178 	acc 0.4952380952 	auroc 0.4968229167 	loss_nll 12730031.0000000000 	loss_mse 0.0639700070 	loss 12730030.0000000000 	inference time 0.2516841888 	time: 5.1970s 	
114 train	 	loss_kl -0.7979799509 	acc 0.4961904762 	auroc 0.4968113426 	loss_nll 12728436.0000000000 	loss_mse 0.0639619902 	loss 12728435.0000000000 	inference time 0.2350254059 	time: 5.3268s 	
115 train	 	loss_kl -0.8100856543 	acc 0.4961904762 	auroc 0.4965046296 	loss_nll 12729720.0000000000 	loss_mse 0.0639684349 	loss 12729719.0000000000 	inference time 0.2577128410 	time: 5.3474s 	
116 train	 	loss_kl -0.8100083470 	acc 0.4971428571 	auroc 0.4963425926 	loss_nll 12728996.0000000000 	loss_mse 0.0639647990 	loss 12728995.0000000000 	inference time 0.3246159554 	time: 5.3377s 	
117 train	 	loss_kl -0.8101708889 	acc 0.5000000000 	auroc 0.4966145833 	loss_nll 12727332.0000000000 	loss_mse 0.0639564395 	loss 12727331.0000000000 	inference time 0.3135402203 	time: 5.3755s 	
118 train	 	loss_kl -0.8120297194 	acc 0.5038095238 	auroc 0.4946006944 	loss_nll 12728730.0000000000 	loss_mse 0.0639634654 	loss 12728729.0000000000 	inference time 0.2587704659 	time: 5.3185s 	
119 train	 	loss_kl -0.7946033478 	acc 0.5038095238 	auroc 0.4936053241 	loss_nll 12723004.0000000000 	loss_mse 0.0639346913 	loss 12723003.0000000000 	inference time 0.2400355339 	time: 5.3445s 	
120 train	 	loss_kl -0.7824607491 	acc 0.5028571429 	auroc 0.4935590278 	loss_nll 12722584.0000000000 	loss_mse 0.0639325753 	loss 12722583.0000000000 	inference time 0.2797164917 	time: 5.3153s 	
121 train	 	loss_kl -0.7686702013 	acc 0.5028571429 	auroc 0.4946296296 	loss_nll 12722313.0000000000 	loss_mse 0.0639312193 	loss 12722312.0000000000 	inference time 0.2885179520 	time: 5.3049s 	
122 train	 	loss_kl -0.7641457915 	acc 0.5028571429 	auroc 0.4958564815 	loss_nll 12719739.0000000000 	loss_mse 0.0639182851 	loss 12719738.0000000000 	inference time 0.2861039639 	time: 5.2983s 	
123 train	 	loss_kl -0.7591963410 	acc 0.5009523810 	auroc 0.4968518519 	loss_nll 12716218.0000000000 	loss_mse 0.0639005899 	loss 12716217.0000000000 	inference time 0.3621068001 	time: 5.4606s 	
124 train	 	loss_kl -0.7604923844 	acc 0.5019047619 	auroc 0.4974826389 	loss_nll 12718331.0000000000 	loss_mse 0.0639112070 	loss 12718330.0000000000 	inference time 0.3440859318 	time: 5.4407s 	
125 train	 	loss_kl -0.7730416059 	acc 0.5019047619 	auroc 0.4979513889 	loss_nll 12721076.0000000000 	loss_mse 0.0639249980 	loss 12721075.0000000000 	inference time 0.2364380360 	time: 5.2842s 	
126 train	 	loss_kl -0.7775811553 	acc 0.5028571429 	auroc 0.4988368056 	loss_nll 12716425.0000000000 	loss_mse 0.0639016256 	loss 12716424.0000000000 	inference time 0.3997120857 	time: 5.4377s 	
127 train	 	loss_kl -0.7784181833 	acc 0.5038095238 	auroc 0.4994502315 	loss_nll 12722501.0000000000 	loss_mse 0.0639321655 	loss 12722500.0000000000 	inference time 0.3896324635 	time: 5.4310s 	
128 train	 	loss_kl -0.7886992693 	acc 0.5057142857 	auroc 0.5000462963 	loss_nll 12739954.0000000000 	loss_mse 0.0640198663 	loss 12739953.0000000000 	inference time 0.3234136105 	time: 5.4309s 	
129 train	 	loss_kl -0.8059752584 	acc 0.5066666667 	auroc 0.5017476852 	loss_nll 12731022.0000000000 	loss_mse 0.0639749840 	loss 12731021.0000000000 	inference time 0.3555464745 	time: 5.4274s 	
130 train	 	loss_kl -0.7677934766 	acc 0.4990476190 	auroc 0.5017534722 	loss_nll 12709465.0000000000 	loss_mse 0.0638666525 	loss 12709464.0000000000 	inference time 0.3605554104 	time: 5.4365s 	
131 train	 	loss_kl -0.7480955720 	acc 0.5009523810 	auroc 0.5019849537 	loss_nll 12715420.0000000000 	loss_mse 0.0638965890 	loss 12715419.0000000000 	inference time 0.3428158760 	time: 5.3996s 	
132 train	 	loss_kl -0.7398840785 	acc 0.4990476190 	auroc 0.5008738426 	loss_nll 12715405.0000000000 	loss_mse 0.0638965070 	loss 12715404.0000000000 	inference time 0.3544130325 	time: 5.3911s 	
133 train	 	loss_kl -0.7521950603 	acc 0.4980952381 	auroc 0.5008391204 	loss_nll 12708666.0000000000 	loss_mse 0.0638626367 	loss 12708665.0000000000 	inference time 0.3533895016 	time: 5.3721s 	
134 train	 	loss_kl -0.7393813729 	acc 0.5009523810 	auroc 0.5024479167 	loss_nll 12708845.0000000000 	loss_mse 0.0638635382 	loss 12708844.0000000000 	inference time 0.3223001957 	time: 5.3923s 	
135 train	 	loss_kl -0.7419361472 	acc 0.5019047619 	auroc 0.5030381944 	loss_nll 12711682.0000000000 	loss_mse 0.0638777912 	loss 12711681.0000000000 	inference time 0.3720016479 	time: 5.3854s 	
136 train	 	loss_kl -0.7414114475 	acc 0.5019047619 	auroc 0.5034722222 	loss_nll 12707931.0000000000 	loss_mse 0.0638589412 	loss 12707930.0000000000 	inference time 0.2490725517 	time: 5.3575s 	
137 train	 	loss_kl -0.7476751804 	acc 0.5028571429 	auroc 0.5048263889 	loss_nll 12707663.0000000000 	loss_mse 0.0638576001 	loss 12707662.0000000000 	inference time 0.2599806786 	time: 5.3309s 	
138 train	 	loss_kl -0.7568491697 	acc 0.5019047619 	auroc 0.5060590278 	loss_nll 12708470.0000000000 	loss_mse 0.0638616607 	loss 12708469.0000000000 	inference time 0.3503243923 	time: 5.3326s 	
139 train	 	loss_kl -0.7460024357 	acc 0.5038095238 	auroc 0.5064236111 	loss_nll 12699374.0000000000 	loss_mse 0.0638159439 	loss 12699373.0000000000 	inference time 0.4064965248 	time: 5.5204s 	
140 train	 	loss_kl -0.7179616094 	acc 0.4990476190 	auroc 0.5066550926 	loss_nll 12706059.0000000000 	loss_mse 0.0638495460 	loss 12706058.0000000000 	inference time 0.2809696198 	time: 5.3042s 	
141 train	 	loss_kl -0.7081853151 	acc 0.5000000000 	auroc 0.5059548611 	loss_nll 12700928.0000000000 	loss_mse 0.0638237596 	loss 12700927.0000000000 	inference time 0.4044289589 	time: 5.4742s 	
142 train	 	loss_kl -0.7389060855 	acc 0.4990476190 	auroc 0.5053761574 	loss_nll 12696110.0000000000 	loss_mse 0.0637995452 	loss 12696109.0000000000 	inference time 0.2975232601 	time: 5.4916s 	
143 train	 	loss_kl -0.7636519670 	acc 0.5019047619 	auroc 0.5065393519 	loss_nll 12698478.0000000000 	loss_mse 0.0638114512 	loss 12698477.0000000000 	inference time 0.3553848267 	time: 5.4717s 	
144 train	 	loss_kl -0.7719839811 	acc 0.5028571429 	auroc 0.5067708333 	loss_nll 12698162.0000000000 	loss_mse 0.0638098642 	loss 12698161.0000000000 	inference time 0.3882119656 	time: 5.4608s 	
145 train	 	loss_kl -0.7715613842 	acc 0.5009523810 	auroc 0.5082523148 	loss_nll 12697853.0000000000 	loss_mse 0.0638083071 	loss 12697852.0000000000 	inference time 0.3322689533 	time: 5.4919s 	
146 train	 	loss_kl -0.7698574662 	acc 0.5000000000 	auroc 0.5074942130 	loss_nll 12698228.0000000000 	loss_mse 0.0638101920 	loss 12698227.0000000000 	inference time 0.4157514572 	time: 5.6297s 	
147 train	 	loss_kl -0.7698509097 	acc 0.4971428571 	auroc 0.5061111111 	loss_nll 12691354.0000000000 	loss_mse 0.0637756437 	loss 12691353.0000000000 	inference time 0.2903163433 	time: 5.4192s 	
148 train	 	loss_kl -0.7842089534 	acc 0.4971428571 	auroc 0.5049652778 	loss_nll 12690772.0000000000 	loss_mse 0.0637727231 	loss 12690771.0000000000 	inference time 0.2375864983 	time: 5.2274s 	
149 train	 	loss_kl -0.8482666016 	acc 0.5019047619 	auroc 0.5021238426 	loss_nll 12691766.0000000000 	loss_mse 0.0637777150 	loss 12691765.0000000000 	inference time 0.3666892052 	time: 5.4205s 	
150 train	 	loss_kl -0.8354433179 	acc 0.5019047619 	auroc 0.4997916667 	loss_nll 12683416.0000000000 	loss_mse 0.0637357607 	loss 12683415.0000000000 	inference time 0.3528847694 	time: 5.3993s 	
151 train	 	loss_kl -0.8483668566 	acc 0.5047619048 	auroc 0.4983101852 	loss_nll 12680460.0000000000 	loss_mse 0.0637209043 	loss 12680459.0000000000 	inference time 0.3712499142 	time: 5.3953s 	
152 train	 	loss_kl -0.8780505657 	acc 0.5019047619 	auroc 0.4995486111 	loss_nll 12685334.0000000000 	loss_mse 0.0637453943 	loss 12685333.0000000000 	inference time 0.3560826778 	time: 5.4270s 	
153 train	 	loss_kl -0.9274790883 	acc 0.4952380952 	auroc 0.4992939815 	loss_nll 12687681.0000000000 	loss_mse 0.0637571886 	loss 12687680.0000000000 	inference time 0.3516135216 	time: 5.3987s 	
154 train	 	loss_kl -0.8869286180 	acc 0.5009523810 	auroc 0.5000173611 	loss_nll 12695508.0000000000 	loss_mse 0.0637965202 	loss 12695507.0000000000 	inference time 0.3524417877 	time: 5.3677s 	
155 train	 	loss_kl -0.8649709225 	acc 0.5000000000 	auroc 0.5012847222 	loss_nll 12688575.0000000000 	loss_mse 0.0637616813 	loss 12688574.0000000000 	inference time 0.3238978386 	time: 5.3962s 	
156 train	 	loss_kl -0.8801023364 	acc 0.5047619048 	auroc 0.5032002315 	loss_nll 12680255.0000000000 	loss_mse 0.0637198761 	loss 12680254.0000000000 	inference time 0.3355252743 	time: 5.3620s 	
157 train	 	loss_kl -0.8852256536 	acc 0.5047619048 	auroc 0.5040335648 	loss_nll 12670792.0000000000 	loss_mse 0.0636723191 	loss 12670791.0000000000 	inference time 0.2544260025 	time: 5.3253s 	
158 train	 	loss_kl -0.8711350560 	acc 0.4980952381 	auroc 0.5029050926 	loss_nll 12673583.0000000000 	loss_mse 0.0636863485 	loss 12673582.0000000000 	inference time 0.2862460613 	time: 5.3806s 	
159 train	 	loss_kl -0.8400374651 	acc 0.5028571429 	auroc 0.5024131944 	loss_nll 12665053.0000000000 	loss_mse 0.0636434779 	loss 12665052.0000000000 	inference time 0.2845172882 	time: 5.3330s 	
160 train	 	loss_kl -0.8223837614 	acc 0.4980952381 	auroc 0.5023148148 	loss_nll 12667638.0000000000 	loss_mse 0.0636564717 	loss 12667637.0000000000 	inference time 0.3852365017 	time: 5.4634s 	
161 train	 	loss_kl -0.8067253232 	acc 0.4923809524 	auroc 0.5021296296 	loss_nll 12662030.0000000000 	loss_mse 0.0636282861 	loss 12662029.0000000000 	inference time 0.2257754803 	time: 5.3372s 	
162 train	 	loss_kl -0.7798543572 	acc 0.4961904762 	auroc 0.5013020833 	loss_nll 12662184.0000000000 	loss_mse 0.0636290684 	loss 12662183.0000000000 	inference time 0.2625701427 	time: 5.2770s 	
163 train	 	loss_kl -0.7806946635 	acc 0.4933333333 	auroc 0.5002025463 	loss_nll 12669128.0000000000 	loss_mse 0.0636639595 	loss 12669127.0000000000 	inference time 0.2349226475 	time: 5.3071s 	
164 train	 	loss_kl -0.7916859388 	acc 0.4942857143 	auroc 0.5028703704 	loss_nll 12667077.0000000000 	loss_mse 0.0636536554 	loss 12667076.0000000000 	inference time 0.4037873745 	time: 5.4712s 	
165 train	 	loss_kl -0.7927815914 	acc 0.4961904762 	auroc 0.5041261574 	loss_nll 12669334.0000000000 	loss_mse 0.0636649951 	loss 12669333.0000000000 	inference time 0.2488982677 	time: 5.2720s 	
166 train	 	loss_kl -0.7521823645 	acc 0.4990476190 	auroc 0.5056944444 	loss_nll 12663988.0000000000 	loss_mse 0.0636381209 	loss 12663987.0000000000 	inference time 0.3501060009 	time: 5.4494s 	
167 train	 	loss_kl -0.7769186497 	acc 0.4961904762 	auroc 0.5076909722 	loss_nll 12667347.0000000000 	loss_mse 0.0636550114 	loss 12667346.0000000000 	inference time 0.3388144970 	time: 5.4058s 	
168 train	 	loss_kl -0.8482183218 	acc 0.4980952381 	auroc 0.5113136574 	loss_nll 12664822.0000000000 	loss_mse 0.0636423230 	loss 12664821.0000000000 	inference time 0.3940856457 	time: 5.4578s 	
169 train	 	loss_kl -0.9089115858 	acc 0.4904761905 	auroc 0.5156481481 	loss_nll 12664373.0000000000 	loss_mse 0.0636400655 	loss 12664372.0000000000 	inference time 0.5458869934 	time: 5.5984s 	
170 train	 	loss_kl -0.8886055946 	acc 0.4923809524 	auroc 0.5184722222 	loss_nll 12663272.0000000000 	loss_mse 0.0636345297 	loss 12663271.0000000000 	inference time 0.3915421963 	time: 5.4293s 	
171 train	 	loss_kl -0.8884554505 	acc 0.4971428571 	auroc 0.5175578704 	loss_nll 12671057.0000000000 	loss_mse 0.0636736527 	loss 12671056.0000000000 	inference time 0.2919816971 	time: 5.4056s 	
172 train	 	loss_kl -0.9662877917 	acc 0.4942857143 	auroc 0.5168865741 	loss_nll 12680760.0000000000 	loss_mse 0.0637224093 	loss 12680759.0000000000 	inference time 0.2371940613 	time: 5.3364s 	
173 train	 	loss_kl -0.9078419209 	acc 0.4933333333 	auroc 0.5187268519 	loss_nll 12673005.0000000000 	loss_mse 0.0636834428 	loss 12673004.0000000000 	inference time 0.3181731701 	time: 5.3495s 	
174 train	 	loss_kl -0.8960373998 	acc 0.4942857143 	auroc 0.5212615741 	loss_nll 12657828.0000000000 	loss_mse 0.0636071712 	loss 12657827.0000000000 	inference time 0.3213701248 	time: 5.3994s 	
175 train	 	loss_kl -0.8204525113 	acc 0.4876190476 	auroc 0.5193229167 	loss_nll 12656459.0000000000 	loss_mse 0.0636002943 	loss 12656458.0000000000 	inference time 0.3908586502 	time: 5.5025s 	
176 train	 	loss_kl -0.8428010345 	acc 0.4847619048 	auroc 0.5198611111 	loss_nll 12662162.0000000000 	loss_mse 0.0636289492 	loss 12662161.0000000000 	inference time 0.2354013920 	time: 5.3745s 	
177 train	 	loss_kl -0.8444771767 	acc 0.4942857143 	auroc 0.5262500000 	loss_nll 12669995.0000000000 	loss_mse 0.0636683181 	loss 12669994.0000000000 	inference time 0.3467600346 	time: 5.4211s 	
178 train	 	loss_kl -0.8698262572 	acc 0.4933333333 	auroc 0.5345138889 	loss_nll 12665517.0000000000 	loss_mse 0.0636458099 	loss 12665516.0000000000 	inference time 0.0713376999 	time: 5.1892s 	
179 train	 	loss_kl -0.8522068858 	acc 0.4857142857 	auroc 0.5407291667 	loss_nll 12672563.0000000000 	loss_mse 0.0636812150 	loss 12672562.0000000000 	inference time 0.3129768372 	time: 5.4574s 	
180 train	 	loss_kl -0.8713747263 	acc 0.4847619048 	auroc 0.5429224537 	loss_nll 12650960.0000000000 	loss_mse 0.0635726526 	loss 12650959.0000000000 	inference time 0.3902907372 	time: 5.4745s 	
181 train	 	loss_kl -0.8685194254 	acc 0.4847619048 	auroc 0.5463541667 	loss_nll 12639789.0000000000 	loss_mse 0.0635165274 	loss 12639788.0000000000 	inference time 0.3109865189 	time: 5.3128s 	
182 train	 	loss_kl -0.8566026092 	acc 0.4885714286 	auroc 0.5489525463 	loss_nll 12639318.0000000000 	loss_mse 0.0635141581 	loss 12639317.0000000000 	inference time 0.3905334473 	time: 5.4313s 	
183 train	 	loss_kl -0.8399657607 	acc 0.4885714286 	auroc 0.5458217593 	loss_nll 12637193.0000000000 	loss_mse 0.0635034814 	loss 12637192.0000000000 	inference time 0.3910744190 	time: 5.4837s 	
184 train	 	loss_kl -0.8823336959 	acc 0.4914285714 	auroc 0.5435243056 	loss_nll 12625170.0000000000 	loss_mse 0.0634430647 	loss 12625169.0000000000 	inference time 0.0706012249 	time: 5.1720s 	
185 train	 	loss_kl -0.8530153632 	acc 0.4990476190 	auroc 0.5430497685 	loss_nll 12632389.0000000000 	loss_mse 0.0634793341 	loss 12632388.0000000000 	inference time 0.2325937748 	time: 5.2999s 	
186 train	 	loss_kl -0.7903285623 	acc 0.5028571429 	auroc 0.5444212963 	loss_nll 12632057.0000000000 	loss_mse 0.0634776726 	loss 12632056.0000000000 	inference time 0.3038237095 	time: 5.4679s 	
187 train	 	loss_kl -0.8071823120 	acc 0.5038095238 	auroc 0.5418692130 	loss_nll 12625374.0000000000 	loss_mse 0.0634440929 	loss 12625373.0000000000 	inference time 0.3699798584 	time: 5.3883s 	
188 train	 	loss_kl -0.8012044430 	acc 0.5095238095 	auroc 0.5342708333 	loss_nll 12620935.0000000000 	loss_mse 0.0634217784 	loss 12620934.0000000000 	inference time 0.2487168312 	time: 5.2822s 	
189 train	 	loss_kl -0.7706508636 	acc 0.5066666667 	auroc 0.5282175926 	loss_nll 12625526.0000000000 	loss_mse 0.0634448528 	loss 12625525.0000000000 	inference time 0.3373825550 	time: 5.4054s 	
190 train	 	loss_kl -0.7551216483 	acc 0.5047619048 	auroc 0.5269097222 	loss_nll 12615309.0000000000 	loss_mse 0.0633935109 	loss 12615308.0000000000 	inference time 0.4119701385 	time: 5.5535s 	
191 train	 	loss_kl -0.7609087825 	acc 0.5019047619 	auroc 0.5223379630 	loss_nll 12620426.0000000000 	loss_mse 0.0634192228 	loss 12620425.0000000000 	inference time 0.3263480663 	time: 5.3670s 	
192 train	 	loss_kl -0.7658264637 	acc 0.5019047619 	auroc 0.5196469907 	loss_nll 12629236.0000000000 	loss_mse 0.0634634942 	loss 12629235.0000000000 	inference time 0.3270542622 	time: 5.3582s 	
193 train	 	loss_kl -0.7457100749 	acc 0.5000000000 	auroc 0.5180034722 	loss_nll 12639332.0000000000 	loss_mse 0.0635142326 	loss 12639331.0000000000 	inference time 0.3273501396 	time: 5.5206s 	
194 train	 	loss_kl -0.7386572361 	acc 0.4980952381 	auroc 0.5222858796 	loss_nll 12645281.0000000000 	loss_mse 0.0635441244 	loss 12645280.0000000000 	inference time 0.3745386600 	time: 5.5035s 	
195 train	 	loss_kl -0.7383124232 	acc 0.4952380952 	auroc 0.5311342593 	loss_nll 12687208.0000000000 	loss_mse 0.0637548119 	loss 12687207.0000000000 	inference time 0.2399797440 	time: 5.3721s 	
196 train	 	loss_kl -0.6994515061 	acc 0.5009523810 	auroc 0.5330381944 	loss_nll 12706835.0000000000 	loss_mse 0.0638534427 	loss 12706834.0000000000 	inference time 0.3083171844 	time: 5.4383s 	
197 train	 	loss_kl -0.6892980337 	acc 0.5000000000 	auroc 0.5329224537 	loss_nll 12808900.0000000000 	loss_mse 0.0643663332 	loss 12808899.0000000000 	inference time 0.3499810696 	time: 5.3727s 	
198 train	 	loss_kl -0.7395357490 	acc 0.4942857143 	auroc 0.5357986111 	loss_nll 12663323.0000000000 	loss_mse 0.0636347905 	loss 12663322.0000000000 	inference time 0.2681674957 	time: 5.3404s 	
199 train	 	loss_kl -0.7374047041 	acc 0.4961904762 	auroc 0.5377719907 	loss_nll 12623997.0000000000 	loss_mse 0.0634371713 	loss 12623996.0000000000 	inference time 0.3835470676 	time: 5.4757s 	
Best Epoch: 0000
